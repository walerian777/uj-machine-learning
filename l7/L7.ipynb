{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L7: Klasyfikacja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na dzisiejszych ćwiczeniach skupimy się na: \n",
    "\n",
    "1. Ewaluacji klasyfikatorów i modeli probabilistycznych na przykładzie rozpoznawania raka piersi\n",
    "2. Różnicach pomiędzy Naive Bayes z regresja logistyczną\n",
    "3. Praktycznym problemie klasyfikacji SPAMu (od wczytania danych do klasyfikatora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import cPickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.learning_curve import learning_curve\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metryki (klasyfikator binarny)\n",
    "\n",
    "Przypomnijmy, że zadaniem uczenia maszynowego jest znalezienie modelu, który minimalizuje loss na zbiorze testowym (notebooki L5 oraz L6). Tutaj zajmujemy się definicjami metryk, z których każda także może być funkcją kosztu.\n",
    "\n",
    "<img width=300 src=\"wyklady2017/mum_figures/precision_recall.png\">\n",
    "\n",
    "Niech $y$ to prawdziwa klasa, a $\\hat{y}$ to predykcja. Najpopularniejsze metryki dla klasyfikatorów binarnych:\n",
    "\n",
    "* Accuracy\n",
    "\n",
    "$$ \\frac{TP + TN}{TN + FN + TP + FP} = p(\\hat{y} = y | x) $$\n",
    "\n",
    "* Precision \n",
    "\n",
    "$$ \\frac{TP}{TP + FP} = p(y=1| \\hat{y}=1) $$\n",
    "\n",
    "* Recall \n",
    "\n",
    "$$ \\frac{TP}{TP + FN} = p(\\hat{y}=1| y=1) $$\n",
    "\n",
    "## Imbalans klas\n",
    "\n",
    "Ref: https://svds.com/learning-imbalanced-classes/\n",
    "\n",
    "Chcemy zdefiniować metryki *zbalansowane*. Przez zbalansowaną metrykę rozumiemy metrykę jak najmniej wrażliwą na \"prior\" klas. [Wytłumaczyć czemu accuracy jest mylące]\n",
    "\n",
    "## Bardziej zaawansowane metryki\n",
    "\n",
    "Kolejne metryki (dla klasyfikatorów binarnych) będą oparte o confusion matrix:\n",
    "\n",
    "<img src=\"figures/L7/confusion_matrix.png\">\n",
    "\n",
    "### Balanced accuracy\n",
    "\n",
    "$$ \\frac{\\mbox{precision} + \\mbox{recall}}{2} $$\n",
    "\n",
    "Idea: Zbalansowana metryka, średnia precision i recall.\n",
    "\n",
    "Problemy:\n",
    "1. nie używa w ogóle TN. \n",
    "2. zwraca wysoki wynik dla danych typu duża przewaga pozytywnych klas i model zwracający zawsze pozytywną klasę (recall i precision wysokie)\n",
    "\n",
    "### F1\n",
    "\n",
    "$$ \\frac{\\mbox{precision} * \\mbox{recall}}{\\mbox{precision} + \\mbox{recall}} $$\n",
    "\n",
    "Idea: Zbalansowana metryka, średnia *harmoniczna* precision i recall.\n",
    "\n",
    "Problemy:\n",
    "1. nie używa w ogóle TN. \n",
    "2. zwraca wysoki wynik dla danych typu duża przewaga pozytywnych klas i model zwracający zawsze pozytywną klasę (recall i precision wysokie)\n",
    "\n",
    "### Matthews correlation coefficient\n",
    "\n",
    "$$ \\frac{TP*TN  - FP*FN}{\\sqrt{(TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)}} $$\n",
    "\n",
    "Idea: Zbalansowana metryka, która używa całej macierzy confusion.\n",
    "\n",
    "Plus: bardziej \"odporna\" na \"głupie\" klasyfikatory.\n",
    "\n",
    "## Funkcja kosztu\n",
    "\n",
    "Na podstawie confusion matrix możemy definiować funkcję kosztu. Ile płacimy za FN? W przypadku klasyfikacji raka, dużo \"tańsze\" jest skierowanie pacjenta na dodatkowe badania niż postawienie fałszywej negatywnej diagnozy!\n",
    "\n",
    "<img width=400 src=\"figures/L7/cost_mat.png\">\n",
    "\n",
    "Oczywiście zazwyczaj $C_{TP}$ oraz $C_{TN}$ jest 0. Funkcja kosztu 0-1 (albo accuracy) odtwarza $C_{FN} = C_{FP}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasyfikacja wrażliwa na koszt\n",
    "\n",
    "Ref: http://web.cs.iastate.edu/~honavar/elkan.pdf\n",
    "\n",
    "Czasami jesteśmy bardziej zainteresowani w precision lub recall. Są to problemy ``cost-sensitive``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>0.372583</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>0.483918</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "count  5.690000e+02  569.000000   569.000000    569.000000      569.000000   \n",
       "mean   3.037183e+07    0.372583    14.127292     19.289649       91.969033   \n",
       "std    1.250206e+08    0.483918     3.524049      4.301036       24.298981   \n",
       "min    8.670000e+03    0.000000     6.981000      9.710000       43.790000   \n",
       "25%    8.692180e+05    0.000000    11.700000     16.170000       75.170000   \n",
       "50%    9.060240e+05    0.000000    13.370000     18.840000       86.240000   \n",
       "75%    8.813129e+06    1.000000    15.780000     21.800000      104.100000   \n",
       "max    9.113205e+08    1.000000    28.110000     39.280000      188.500000   \n",
       "\n",
       "         area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "count   569.000000       569.000000        569.000000      569.000000   \n",
       "mean    654.889104         0.096360          0.104341        0.088799   \n",
       "std     351.914129         0.014064          0.052813        0.079720   \n",
       "min     143.500000         0.052630          0.019380        0.000000   \n",
       "25%     420.300000         0.086370          0.064920        0.029560   \n",
       "50%     551.100000         0.095870          0.092630        0.061540   \n",
       "75%     782.700000         0.105300          0.130400        0.130700   \n",
       "max    2501.000000         0.163400          0.345400        0.426800   \n",
       "\n",
       "       concave points_mean           ...             radius_worst  \\\n",
       "count           569.000000           ...               569.000000   \n",
       "mean              0.048919           ...                16.269190   \n",
       "std               0.038803           ...                 4.833242   \n",
       "min               0.000000           ...                 7.930000   \n",
       "25%               0.020310           ...                13.010000   \n",
       "50%               0.033500           ...                14.970000   \n",
       "75%               0.074000           ...                18.790000   \n",
       "max               0.201200           ...                36.040000   \n",
       "\n",
       "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       compactness_worst  concavity_worst  concave points_worst  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       symmetry_worst  fractal_dimension_worst  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/L7/breast_cancer_transformer.csv\")\n",
    "data.drop(\"Unnamed: 32\",axis=1,inplace=True)\n",
    "data['diagnosis']=data['diagnosis'].map({'M':1,'B':0})\n",
    "data.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10dc4cd50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFJCAYAAABKLF7JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAF7hJREFUeJzt3X9s1IX9x/HXtder0F5HFy7GhB0CoyNCLnRrYEkDAUet\ncbLJjx728FwomdCwkDZqKB0UTR2DMHGOAE6zH0mJuzXW+EWzH5kFQwKsmZ3SwNItaZDEH2FnVsLd\n1VzFfr5/LHZj6B32rr33Hc/HX/bu07v35y3hyaceH12O4zgCAAA5VZTrAQAAAEEGAMAEggwAgAEE\nGQAAAwgyAAAGEGQAAAxw5/LNo9FYVl+vsnK6hodHsvqatyL2mDl2mDl2mDl2mLls79Dn837ucwV1\nhex2F+d6hILAHjPHDjPHDjPHDjM3lTssqCADAJCvCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABB\nBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABiQ0//bU7atfvT/cj1CWr9suzvXIwAADOIKGQAA\nAwgyAAAGpP2R9SeffKJdu3bp4sWLcrlcevLJJ3Xt2jVt2bJFd955pySpsbFR9913n7q7uxWJROR2\nu9Xc3KyVK1dO9vwAABSEtEE+efKkJCkSiaivr0/PPPOM7r77bm3atElNTU3jx0WjUXV1damnp0fJ\nZFKhUEi1tbXyeDyTNz0AAAUibZBXrVqlFStWSJLef/99VVRU6Pz587p48aJ6e3s1e/Zstbe3a2Bg\nQNXV1fJ4PPJ4PPL7/RocHFQgEJjscwAAIO/d1Kes3W63duzYoT/96U/62c9+psuXL6uhoUGLFi3S\n0aNHdfjwYS1YsEBer3f8e8rKyhSPx1O+bmXldLndxZmdQZ7x+bzpDzIgX+a0jB1mjh1mjh1mbqp2\neNN/7Wn//v167LHHFAwGFYlEdPvtt0uS6urq1NnZqZqaGiUSifHjE4nEdYH+LMPDIxMcO39Fo7Fc\nj5CWz+fNizktY4eZY4eZY4eZy/YOU8U97aesX3nlFf385z+XJE2bNk0ul0s/+MEPNDAwIEk6e/as\nFi5cqEAgoP7+fiWTScViMQ0NDamqqipLpwAAQGFLe4V8zz33aOfOndq4caOuXbum9vZ23XHHHers\n7FRJSYlmzpypzs5OlZeXKxwOKxQKyXEctba2qrS0dCrOAQCAvJc2yNOnT9ezzz57w+ORSOSGx4LB\noILBYHYmAwDgFsKNQQAAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAw\ngCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIAB\nBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAxw\npzvgk08+0a5du3Tx4kW5XC49+eSTKi0tVVtbm1wul+bPn689e/aoqKhI3d3dikQicrvdam5u1sqV\nK6fiHAAAyHtpg3zy5ElJUiQSUV9fn5555hk5jqOWlhYtXbpUHR0d6u3t1eLFi9XV1aWenh4lk0mF\nQiHV1tbK4/FM+kkAAJDv0gZ51apVWrFihSTp/fffV0VFhc6cOaMlS5ZIkpYvX67Tp0+rqKhI1dXV\n8ng88ng88vv9GhwcVCAQmNQTAACgENzUf0N2u93asWOHOjs7tXr1ajmOI5fLJUkqKytTLBZTPB6X\n1+sd/56ysjLF4/HJmRoAgAKT9gr5U/v379djjz2mYDCoZDI5/ngikVBFRYXKy8uVSCSue/y/A/1Z\nKiuny+0unsDY+cvnS70TK/JlTsvYYebYYebYYeamaodpg/zKK6/o8uXL2rJli6ZNmyaXy6VFixap\nr69PS5cu1alTp/TNb35TgUBAP/3pT5VMJjU6OqqhoSFVVVWlfO3h4ZGsnUi+iEZjuR4hLZ/Pmxdz\nWsYOM8cOM8cOM5ftHaaKe9og33PPPdq5c6c2btyoa9euqb29XfPmzdPu3bt18OBBzZ07V/X19Sou\nLlY4HFYoFJLjOGptbVVpaWnWTgIAgEKWNsjTp0/Xs88+e8Pjx44du+GxYDCoYDCYnckAALiFcGMQ\nAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCAD\nAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkA\nAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGuFM9+fHHH6u9\nvV3vvfeeRkdH1dzcrDvuuENbtmzRnXfeKUlqbGzUfffdp+7ubkUiEbndbjU3N2vlypVTMT8AAAUh\nZZCPHz+uGTNm6MCBA7py5YoeeOABbdu2TZs2bVJTU9P4cdFoVF1dXerp6VEymVQoFFJtba08Hs+k\nnwAAAIUgZZDvvfde1dfXS5Icx1FxcbHOnz+vixcvqre3V7Nnz1Z7e7sGBgZUXV0tj8cjj8cjv9+v\nwcFBBQKBKTkJAADyXcogl5WVSZLi8bi2b9+ulpYWjY6OqqGhQYsWLdLRo0d1+PBhLViwQF6v97rv\ni8fjad+8snK63O7iDE8hv/h83vQHGZAvc1rGDjPHDjPHDjM3VTtMGWRJ+uCDD7Rt2zaFQiGtXr1a\nV69eVUVFhSSprq5OnZ2dqqmpUSKRGP+eRCJxXaA/z/DwSAaj56doNJbrEdLy+bx5Madl7DBz7DBz\n7DBz2d5hqrin/JT1hx9+qKamJj3++ONav369JGnz5s0aGBiQJJ09e1YLFy5UIBBQf3+/ksmkYrGY\nhoaGVFVVlbUTAACg0KW8Qn7uued09epVHTlyREeOHJEktbW1ae/evSopKdHMmTPV2dmp8vJyhcNh\nhUIhOY6j1tZWlZaWTskJAABQCFyO4zi5evNs/yilad+JrL7eZPhl2925HiEtfsyVOXaYOXaYOXaY\nOTM/sgYAAFODIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEG\nAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIA\nAAYQZAAADCDIAAAYQJABADCAIAMAYIA71wMAAG5dTftO5HqElF59+rtT9l5cIQMAYABBBgDAAIIM\nAIABBBkAAAMIMgAABqT8lPXHH3+s9vZ2vffeexodHVVzc7O++tWvqq2tTS6XS/Pnz9eePXtUVFSk\n7u5uRSIRud1uNTc3a+XKlVN1DgAA5L2UQT5+/LhmzJihAwcO6MqVK3rggQe0YMECtbS0aOnSpero\n6FBvb68WL16srq4u9fT0KJlMKhQKqba2Vh6PZ6rOAwCAvJYyyPfee6/q6+slSY7jqLi4WBcuXNCS\nJUskScuXL9fp06dVVFSk6upqeTweeTwe+f1+DQ4OKhAITP4ZAABQAFIGuaysTJIUj8e1fft2tbS0\naP/+/XK5XOPPx2IxxeNxeb3e674vHo+nffPKyulyu4szmT/v+Hze9AcZkC9zWsYOM8cOM8cOMzdV\nO0x7p64PPvhA27ZtUygU0urVq3XgwIHx5xKJhCoqKlReXq5EInHd4/8d6M8zPDwywbHzVzQay/UI\nafl83ryY0zJ2mDl2mDl2mB3Z3GGquKf8lPWHH36opqYmPf7441q/fr0k6a677lJfX58k6dSpU6qp\nqVEgEFB/f7+SyaRisZiGhoZUVVWVtRMAAKDQpbxCfu6553T16lUdOXJER44ckST98Ic/1FNPPaWD\nBw9q7ty5qq+vV3FxscLhsEKhkBzHUWtrq0pLS6fkBAAAKAQpg7xr1y7t2rXrhsePHTt2w2PBYFDB\nYDB7kwEAcAvhxiAAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQ\nAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIM\nAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQA\nAAy4qSCfO3dO4XBYkvS3v/1Ny5YtUzgcVjgc1u9+9ztJUnd3t9auXatgMKiTJ09O3sQAABQgd7oD\nXnjhBR0/flzTpk2TJF24cEGbNm1SU1PT+DHRaFRdXV3q6elRMplUKBRSbW2tPB7P5E0OAEABSXuF\n7Pf7dejQofGvz58/rzfeeEMbN25Ue3u74vG4BgYGVF1dLY/HI6/XK7/fr8HBwUkdHACAQpL2Crm+\nvl7vvvvu+NeBQEANDQ1atGiRjh49qsOHD2vBggXyer3jx5SVlSkej6d988rK6XK7iyc4en7y+bzp\nDzIgX+a0jB1mjh1mjh1mbqp2mDbI/6uurk4VFRXj/9zZ2amamholEonxYxKJxHWB/jzDwyNf9O3z\nXjQay/UIafl83ryY0zJ2mDl2mDl2mB3Z3GGquH/hT1lv3rxZAwMDkqSzZ89q4cKFCgQC6u/vVzKZ\nVCwW09DQkKqqqiY+MQAAt5gvfIX8xBNPqLOzUyUlJZo5c6Y6OztVXl6ucDisUCgkx3HU2tqq0tLS\nyZgXAICCdFNBnjVrlrq7uyVJCxcuVCQSueGYYDCoYDCY3ekAALhFcGMQAAAMIMgAABhAkAEAMIAg\nAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZ\nAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgA\nABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAG3FSQz507p3A4LEm6dOmSGhsbFQqFtGfP\nHo2NjUmSuru7tXbtWgWDQZ08eXLyJgYAoAClDfILL7ygXbt2KZlMSpJ+/OMfq6WlRS+++KIcx1Fv\nb6+i0ai6uroUiUT0i1/8QgcPHtTo6OikDw8AQKFIG2S/369Dhw6Nf33hwgUtWbJEkrR8+XKdOXNG\nAwMDqq6ulsfjkdfrld/v1+Dg4ORNDQBAgXGnO6C+vl7vvvvu+NeO48jlckmSysrKFIvFFI/H5fV6\nx48pKytTPB5P++aVldPldhdPZO685fN50x9kQL7MaRk7zBw7zBw7zNxU7TBtkP9XUdF/LqoTiYQq\nKipUXl6uRCJx3eP/HejPMzw88kXfPu9Fo7Fcj5CWz+fNizktY4eZY4eZY4fZkc0dpor7F/6U9V13\n3aW+vj5J0qlTp1RTU6NAIKD+/n4lk0nFYjENDQ2pqqpq4hMDAHCL+cJXyDt27NDu3bt18OBBzZ07\nV/X19SouLlY4HFYoFJLjOGptbVVpaelkzAsAQEG6qSDPmjVL3d3dkqQ5c+bo2LFjNxwTDAYVDAaz\nOx0AALcIbgwCAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAA\nAwgyAAAGEGQAAAwgyAAAGECQAQAwgCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAY\nQJABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAA\n90S/cc2aNSovL5ckzZo1S1u3blVbW5tcLpfmz5+vPXv2qKiI3gMAcDMmFORkMinHcdTV1TX+2Nat\nW9XS0qKlS5eqo6NDvb29qqury9qgAAAUsgldwg4ODuqjjz5SU1OTHn74Yb399tu6cOGClixZIkla\nvny5zpw5k9VBAQAoZBO6Qr7tttu0efNmNTQ06J133tH3v/99OY4jl8slSSorK1MsFkv7OpWV0+V2\nF09khLzl83lzPcJNyZc5LWOHmWOHmWOHmZuqHU4oyHPmzNHs2bPlcrk0Z84czZgxQxcuXBh/PpFI\nqKKiIu3rDA+PTOTt81o0mv4PKrnm83nzYk7L2GHm2GHm2GF2ZHOHqeI+oR9Zv/TSS9q3b58k6fLl\ny4rH46qtrVVfX58k6dSpU6qpqZnISwMAcEua0BXy+vXrtXPnTjU2Nsrlcmnv3r2qrKzU7t27dfDg\nQc2dO1f19fXZnhUAgII1oSB7PB49/fTTNzx+7NixjAcCAOBWxF8UBgDAAIIMAIABBBkAAAMIMgAA\nBhBkAAAMIMgAABhAkAEAMIAgAwBgAEEGAMAAggwAgAEEGQAAAwgyAAAGEGQAAAwgyAAAGECQAQAw\ngCADAGAAQQYAwACCDACAAQQZAAADCDIAAAYQZAAADCDIAAAYQJABADCAIAMAYABBBgDAAIIMAIAB\nBBkAAAMIMgAABhBkAAAMIMgAABhAkAEAMIAgAwBggDubLzY2NqYnnnhCf//73+XxePTUU09p9uzZ\n2XwLAAAKUlavkF9//XWNjo7qt7/9rR599FHt27cvmy8PAEDBymqQ+/v7tWzZMknS4sWLdf78+Wy+\nPAAABSurP7KOx+MqLy8f/7q4uFjXrl2T2/3Zb+PzebP59nr16e9m9fVuZdn+d3MrYoeZY4eZs77D\nfPh9e6p2mNUr5PLyciUSifGvx8bGPjfGAADgP7Ia5K9//es6deqUJOntt99WVVVVNl8eAICC5XIc\nx8nWi336Ket//OMfchxHe/fu1bx587L18gAAFKysBhkAAEwMNwYBAMAAggwAgAF5GeSxsTF1dHRo\nw4YNCofDunTp0nXPnzhxQuvWrdOGDRvU3d2doyltS7fD1157TQ0NDXrwwQfV0dGhsbGxHE1qV7od\nfmr37t36yU9+MsXT5Yd0OxwYGFAoFFJjY6O2b9+uZDKZo0ntSrfD48ePa82aNVq3bp1efPHFHE2Z\nH86dO6dwOHzD41PWFCcP/fGPf3R27NjhOI7jvPXWW87WrVvHnxsdHXVWrVrlXLlyxUkmk87atWud\naDSaq1HNSrXDjz76yPnWt77ljIyMOI7jOK2trc7rr7+ekzktS7XDT/3mN79xgsGgc+DAgakeLy+k\n2uHY2Jjzne98x3nnnXccx3Gc7u5uZ2hoKCdzWpbu12Ftba0zPDzsJJPJ8d8bcaPnn3/euf/++52G\nhobrHp/KpuTlFXKqO4INDQ3J7/frS1/6kjwej77xjW/oL3/5S65GNSvVDj0ejyKRiKZNmyZJunbt\nmkpLS3Myp2Xp7kz317/+VefOndOGDRtyMV5eSLXDixcvasaMGfr1r3+thx56SFeuXNHcuXNzNapZ\n6X4dfu1rX1MsFtPo6Kgcx5HL5crFmOb5/X4dOnTohsensil5GeTPuyPYp895vf+5q0pZWZni8fiU\nz2hdqh0WFRVp5syZkqSuri6NjIyotrY2J3NalmqH//znP3X48GF1dHTkary8kGqHw8PDeuutt/TQ\nQw/pV7/6lf785z/r7NmzuRrVrFQ7lKT58+dr3bp1+va3v60VK1aooqIiF2OaV19f/5k3sprKpuRl\nkFPdEex/n0skEtctE/+W7q5qY2Nj2r9/v06fPq1Dhw7xp+rPkGqHf/jDHzQ8PKxHHnlEzz//vF57\n7TW9/PLLuRrVrFQ7nDFjhmbPnq158+appKREy5Yt4/74nyHVDgcHB/XGG2+ot7dXJ06c0L/+9S/9\n/ve/z9WoeWkqm5KXQU51R7B58+bp0qVLunLlikZHR/Xmm2+quro6V6Oale6uah0dHUomkzpy5Mj4\nj65xvVQ7fPjhh/Xyyy+rq6tLjzzyiO6//36tXbs2V6OalWqHX/nKV5RIJMY/pPTmm29q/vz5OZnT\nslQ79Hq9uu2221RaWqri4mJ9+ctf1tWrV3M1al6ayqbk5Y2m6+rqdPr0aT344IPjdwR79dVXNTIy\nog0bNqitrU2bN2+W4zhat26dbr/99lyPbE6qHS5atEgvvfSSampq9L3vfU/SvwNTV1eX46ltSffr\nEOml2+GPfvQjPfroo3IcR9XV1VqxYkWuRzYn3Q43bNigUCikkpIS+f1+rVmzJtcj54VcNIU7dQEA\nYEBe/sgaAIBCQ5ABADCAIAMAYABBBgDAAIIMAIABBBkAAAMIMgAABhBkAAAM+H8Rkd9ChcRgfQAA\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10db60e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['diagnosis'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Wybieramy cechy\n",
    "prediction_var = ['texture_mean','perimeter_mean','smoothness_mean','compactness_mean','symmetry_mean']\n",
    "train, test = train_test_split(data, test_size = 0.3)# in this our main data is splitted into train and test\n",
    "train_X = train[prediction_var][0:100]\n",
    "train_y=train.diagnosis[0:100]\n",
    "test_X= test[prediction_var] \n",
    "test_y =test.diagnosis  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918128654971\n",
      "0.852459016393\n",
      "0.912280701754\n",
      "0.222958763747\n"
     ]
    }
   ],
   "source": [
    "# Regresja logistyczna\n",
    "model = LogisticRegression(C=50)\n",
    "model.fit(train_X,train_y)\n",
    "pred = model.predict(test_X)\n",
    "print metrics.accuracy_score(pred, test_y)\n",
    "print metrics.precision_score(pred, test_y)\n",
    "print metrics.recall_score(pred, test_y)\n",
    "print metrics.log_loss(test_y, model.predict_proba(test_X)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1 [3 pkt]\n",
    "\n",
    "1. Powyższy model ma istotnie wyższy recall niż precision. \n",
    "\n",
    "Zdefiniujmy jako model probabilistyczny model, który zwraca p($\\hat{y}$ | y). Obiekt LogisticRegression zwraca tą wartość funkcją ``predict_proba``\n",
    "\n",
    "1. Każdy model probabilistyczny można użyć do stworzenia klasyfikora, która może mieć precision 100% lub recall 100% trywialnie, jak? \n",
    "\n",
    "2. Krzywa precision/recall jest obliczana licząc precision oraz recall modelu probabilistycznego dla różnych wartości precision. Zarysuj wykres precision/recall dla modelu powyżej.\n",
    "\n",
    "Powinno wyjść:\n",
    "\n",
    "<img src=\"figures/L7/prec_recall.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD3CAYAAAAALt/WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkgpnkEtS4QxySSqcQS5JhTPIJalw/x8a+VhXdwtDuwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10dea16d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogisticRegression(C = 50)\n",
    "model.fit(train_X, train_y)\n",
    "\n",
    "pred = model.predict_proba(test_X)\n",
    "results = precision_recall_curve(test_y, pred[:, 1])\n",
    "precision = results[0]\n",
    "recall = results[1]\n",
    "thresholds = results[2]\n",
    "\n",
    "\n",
    "_ = plt.plot(recall, precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2 [3 pkt]\n",
    "\n",
    "Założmy, że $C_{FP}$ = 1 i $C_{FN}$ = 10, co odpowiada sytuacji w której nie przejmujemy się postawieniem fałszywej pozytywnej diagnozy.\n",
    "\n",
    "Według http://web.cs.iastate.edu/~honavar/elkan.pdf wystarczy w takim wypadku dodać przykładom odpowiednią wage.\n",
    "\n",
    "a) Przetestuj pare wag klasy negatywnej przez podanie argumentu class_weight do LogisticRegression. Dla każdej wartości wagi narysuj dokładność (accuracy) oraz wynik metryki FN_aversive. Powinno wyjść:\n",
    "\n",
    "<img src=\"figures/L7/fn_aversive.png\">\n",
    "\n",
    "b) Równoważnym sposobem tworzenia \"cost-sensitive\" klasyfikatora z modelu probabilistycznego jest zmiana progu (patrz Zadanie 1). Znajdź taki próg, aby wynik klasyfikatora z tym progiem był równoważny argumentowi class_weight, który daje w punkcie a) najlepszy wynik.\n",
    "\n",
    "Podpowiedź: Jeśli 2 sprawia problem, przejrzyj załączoną publikację"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FN_aversive(y_true, y_pred):\n",
    "    FN = sum((y_true == 1) * (y_pred != y_true))\n",
    "    FP = sum((y_true == 0) * (y_pred != y_true))\n",
    "    return 10 * FN + FP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metryki c.d. (model probabilistyczny)\n",
    "\n",
    "Metryki wcześniej wprowadzone zakładają na wejściu klasyfikator, albo model probabilistyczny z dobranym na twardo thresholdem. Trochę bardziej skomplikowanym modelem może być model probabilistyczny, który zwraca jedynie prawdopodobieństwo\n",
    "\n",
    "## Entropia krzyżowa/log loss (dla klasyfikacji binarnej)\n",
    "\n",
    "Entropia krzyżowa, inaczej log loss jest niczym innym jak dobrze nam znanym log likelihood modelu zastosowanym do modeli probabilistycznych (zwracających prawdopodobieństwo):\n",
    "\n",
    "$$ LL(\\hat y, y) = CE(\\hat y, y) = \\sum_{i=1}^{N} y \\log\\hat(y) $$.\n",
    "\n",
    "Entropia krzyżowa może być też bezpośrednio optymalizowana, w odróżnieniu od metryk typu accuracy, precision czy recall.\n",
    "\n",
    "Warto wspomnieć, że niektóre modele mają dobre accuracy, ale słaby log loss (np. Naive Bayes).\n",
    "\n",
    "## ROC\n",
    "\n",
    "Krzywa ROC tworzona jest podobnie jak krzywa precision recall, tylko tym razem dla każdego progu liczymy true positive rate (p oraz false positive rate.\n",
    "\n",
    "<img src=\"figures/L7/roc_curve.png\">\n",
    "\n",
    "Czasami chcemy opisać krzywą ROC jedną liczbą, z oczywistych względów musimy coś \"oszukać\" (tj. stracić jakąś informację). Popularny sposób to pole powierzni pod krzywą ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes vs Regresja Logistyczna \n",
    "\n",
    "Ref: https://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wyprowadzenie\n",
    "\n",
    "[Wyprowadzić na zajęciach]\n",
    "\n",
    "**Wyprowadzenie zaczynamy od zdefiniowania procesu generowania danych**\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "Zakładamy niezależność cech\n",
    "\n",
    "$$ p(X | Y) = \\prod_i P(X_i | Y) $$\n",
    "\n",
    "### Regresja logistyczna (binarna)\n",
    "\n",
    "Zdefiniujmy ``odds`` jako\n",
    "\n",
    "$$ o = \\frac{p(Y=1 | x)}{p(Y=0| x)} $$\n",
    "\n",
    "Wtedy regresja logistyczna definiuje:\n",
    "\n",
    "$$ \\log(o) = \\sum \\theta_i x_i $$\n",
    "\n",
    "**Teraz liczymy likelihood**\n",
    "\n",
    "### Naive Bayes\n",
    "\n",
    "Naive Bayes to model generatywny (co jak dowiemy się niedługo ma wady). Użyjmy reguły Bayesa aby policzyć likelihood:\n",
    "\n",
    "$$ p(Y | X) = P(X | Y) P(Y)  = ( \\prod_i P(X_i | Y)) P(Y) $$\n",
    "\n",
    "### Regresja logistyczna\n",
    "\n",
    "Przekształcając $$ \\log(o) = \\sum \\theta_i x_i $$ otrzymujemy *bezpośrednio*, że $$ p(y | x) = \\mbox{sigmoid}(\\sum \\theta_i x_i) $$, gdzie $sigmoid(a) = \\frac{1}{1 + \\exp(-a)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Różnice pomiędzy Naive Bayes a regresją logistyczną\n",
    "\n",
    "### Niezależność cech\n",
    "\n",
    "Naive Bayes zakłada niezależność cech (brak korekty liniowych zależności). Mówiąc inaczej możemy \"wrzucić\" do regresji logistycznej skorelowane cechy i się nic nie stanie. W przypadku modelu Naive Bayes nazywamy ten problem \"double counting\".\n",
    "\n",
    "\n",
    "### Model dyskryminatywny vs generatywny\n",
    "\n",
    "Przez model generatywny rozumiem model, który optymalizuje łączne prawdopodobieństwo p(x, y).\n",
    "\n",
    "**Obserwacja 1.** Modelowanie p(x | y) lub p(x) nie jest bezpośrednio niezbędne do modelowania p(y | x). \n",
    "\n",
    "Obserwacja 1. mówi nam, że model generatywny wykonuje \"dodatkową\" pracę. W związku z tym czemu modele generatywne są aktywnie wykorzystywane w praktyce? Jest to po prostu kolejny sposób regularyzacji! Modelując p(x | y) można (niezbyt ściśle) powiedzieć, że modelujemy sposób w jaki funkcjonuje świat. Zainteresowanych odsyłamy do https://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf oraz [TODO]\n",
    "\n",
    "Naive Bayes to *model generatywny*, a *regresja logistyczna* to model dyskryminatywny. W związku z tym należy oczekiwać, że w granicy danych regresja logistyczna będzie osiągać lepsze wyniki, ale może być różnie w przypadku małej ilości danych\n",
    "\n",
    "<img src=\"figures/L7/ng_plot.png\">\n",
    "\n",
    "(Obrazek za https://ai.stanford.edu/~ang/papers/nips01-discriminativegenerative.pdf).\n",
    "\n",
    "### Log loss\n",
    "\n",
    "Naive Bayes daje zbyt optymistyczne prawdopodobieństwa. Jest dobry w accuracy, ale zły w log lossie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.883040935673\n",
      "0.847457627119\n",
      "0.819672131148\n",
      "0.577600587379\n"
     ]
    }
   ],
   "source": [
    "# Przykład słabego log lossu modelu Naive Bayes\n",
    "model = GaussianNB()\n",
    "model.fit(train_X,train_y)\n",
    "pred = model.predict(test_X)\n",
    "print metrics.accuracy_score(test_y, pred,)\n",
    "print metrics.precision_score(test_y, pred)\n",
    "print metrics.recall_score(test_y, pred)\n",
    "# Regresja logistyczna osiąga 0.26\n",
    "print metrics.log_loss(test_y, model.predict_proba(test_X)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3 [3 pkt]\n",
    "\n",
    "Naive Bayes jest często stosowany do problemów klasyfikacyjnych na tekście. W tym zadaniu zajmiemy się klasyfikacją SPAMU. Na wejściu zadany jest test wiadomości e-mail, etykietą jest 0 (prawdziwa wiadomość, \"HAM\") lub 1 (SPAM). \n",
    "\n",
    "Podstawowym problemem jest sposób reprezentacji tekstu. Podobnie jak w przypadku rozważanych funkcji bazowych na wcześniejszych zajęciach, modele wymagają stałowymiarowego wektoru. Proszę użyć klasy CountVectorizer z sklearn w celu przekształcenia wiadomości do reprezentacji wektorowej.\n",
    "\n",
    "1. Zastosuj transformację tekstu do reprezentacji bag of words\n",
    "2. Naucz model Naive Bayes (MultinomialNB) przewidywać SPAM\n",
    "3. Pokaż problem \"double counting\" w modelu Naive Bayes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Załadowanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "messages = pd.read_csv('../data/L7/SMSSpamCollection/SMSSpamCollection', sep='\\t', quoting=csv.QUOTE_NONE,\n",
    "                           names=[\"label\", \"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksploracja danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">ham</th>\n",
       "      <th>count</th>\n",
       "      <td>4827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">spam</th>\n",
       "      <th>count</th>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        message\n",
       "label                                                          \n",
       "ham   count                                                4827\n",
       "      unique                                               4518\n",
       "      top                                Sorry, I'll call later\n",
       "      freq                                                   30\n",
       "spam  count                                                 747\n",
       "      unique                                                653\n",
       "      top     Please call our customer service representativ...\n",
       "      freq                                                    4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                            message  length\n",
      "0   ham  Go until jurong point, crazy.. Available only ...     111\n",
      "1   ham                      Ok lar... Joking wif u oni...      29\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
      "3   ham  U dun say so early hor... U c already then say...      49\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...      61\n"
     ]
    }
   ],
   "source": [
    "messages['length'] = messages['message'].map(lambda text: len(text))\n",
    "print messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x112057a10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD3CAYAAAAHQMOGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlcAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1117b3e90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.length.plot(bins=20, kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x1117dfbd0>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x1120f3790>], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEMCAYAAAArnKpYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqfL/ASnb9aT/LGtvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111679690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages.hist(column='length', by='label', bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przetworzenie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (5574, 8713)\n",
      "number of non-zeros: 74169\n",
      "sparsity: 0.15%\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(analyzer = 'word')\n",
    "messages_bow = count_vectorizer.fit_transform(messages['message'])\n",
    "print 'sparse matrix shape:', messages_bow.shape\n",
    "print 'number of non-zeros:', messages_bow.nnz\n",
    "print 'sparsity: %.2f%%' % (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_detector = MultinomialNB()\n",
    "mapped_messages = map(lambda word: 0 if word == 'spam' else 1, messages['label'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(messages_bow, mapped_messages, test_size = 0.3)\n",
    "spam_detector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.980872683802\n",
      "confusion matrix\n",
      "0.980872683802\n"
     ]
    }
   ],
   "source": [
    "actual_pred = spam_detector.predict(X_test)\n",
    "print 'accuracy', accuracy_score(actual_pred, y_test)\n",
    "print 'confusion matrix\\n', accuracy_score(actual_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
