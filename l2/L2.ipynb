{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motywacja\n",
    "\n",
    "Sieci neuronowe działają, ponieważ efektywnie aproksymują pewne rozkłady prawdopodobieństwa. Celem tych ćwiczeń jest zrozumienie, co konkretnie jest aproksymowane (chwilowo nie interesuje nas, w jaki sposób).\n",
    "Wiedza ta jest potrzebna, aby dobrze zaplanować architekturę modelu i poprawnie wybrać funkcję kosztu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modele generatywne\n",
    "\n",
    "Zadaniem modeli generatywnych jest generowanie danych podobnych (pochodzących z tego samego rozkładu) do tych, które były obserwowane podczas uczenia.\n",
    "\n",
    "Do tej pory omawialiśmy modele dyskryminatywne - one z kolei uczą się \"opisywać\" dane, np. przypisując im klasę, do jakiej należą.\n",
    "\n",
    "Przykładowy efekt działania modelu generatywnego - zdjęcia sypialni\n",
    "\n",
    "<img src=\"figures/L2/gan2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model generatywny rzutu monetą.\n",
    "\n",
    "Spróbujmy wytrenować model generatywny pewnej (być może niesymetrycznej) monety.\n",
    "\n",
    "Obserwacje to wyniki kolejnych rzutów monetą. Na ich podstawie model estymuje rozkład prawdopodobieństwa, z jakiego one pochodzą, czyli po prostu prawdopodobieństwo wylosowania orła - oznaczmy je literą $\\theta$. Uczenie modelu to estymowanie tego parametru.\n",
    "\n",
    "Następnie model może **generować** wyniki kolejnych rzutów. W tym wypadku jest to bardzo proste, wystarczy np. użyć generatora liczb losowych, który z prawdopodobieństwem $\\theta$ wypisze ORZEŁ, a z prawdopodobieństwem $1-\\theta$ będzie to RESZKA.\n",
    "\n",
    "Jeśli na przykład prawdziwe $\\theta$ wynosi $70\\%$, a wyestymowane $60\\%$, to zauważymy, że generowane dane nie są podobne do danych prawdziwych - ORZEŁ będzie pojawiał się zbyt rzadko. Jest to analogia do powyższych zdjęć sypialni. Poprawnie wytrenowany model będzie średnio generował tyle samo ORŁÓW, co prawdziwa moneta i w tym sensie dane pochodzące z modelu będą dla nas nieodróżnialne od danych prawdziwych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W powyższym przykładzie estymowany rozkład jest dyskretny (dwie możliwości: ORZEŁ i RESZKA), natomiast parametr $\\theta$ teoretycznie może przyjmować dowolną wartość z przedziału $[0,1]$ (a więc jest ciągły).\n",
    "\n",
    "Z uwagi na architekturę komputerów w praktyce wszystkie rozkłady i parametry zawsze będą dyskretne, liczba możliwych wartości $\\theta$ będzie zależeć przede wszystkim od precyzji użytych floatów.\n",
    "\n",
    "Rozpatrywanie wszystkich możliwych wartości parametrów jest oczywiście zbyt czasochłonne. Stosuje się więc przybliżenia, a w tym celu łatwiej myśleć o parametrach jako wielkościach ciągłych i korzystać z twierdzeń analizy matematycznej. Podobna uwaga dotyczy rozkładów prawdopodobieństwa - dla przykładu, jeśli chcemy wylosować obrazek, to myślimy o pikselach jako punktach pochodzących z ciągłej trójwymiarowej kostki (kolor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podejście maximum likelihood\n",
    "\n",
    "Załóżmy, że w $10$ rzutach monetą otrzymaliśmy $7$ orłów i $3$ reszki (rzuty są od siebie niezależne, więc istotna jest tylko sumaryczna liczba orłów i reszek, a nie kolejność wyników).\n",
    "\n",
    "Zdefiniujmy funkcję likelihood:\n",
    "$$L(\\theta|\\mathrm{obserwacje}) := P(\\mathrm{obserwacje}|\\theta)$$\n",
    "\n",
    "Chcemy tak dobrać $\\theta$, aby zmaksymalizować $L$ - innymi słowy wybieramy taką wartość $\\theta$, przy której mielibyśmy największe szanse na uzyskanie wyników, które zaobserwowaliśmy.\n",
    "\n",
    "$$L(\\theta|\\mathrm{obserwacje}) = P(\\mathrm{siedem~orłów~i~trzy~reszki}|\\theta) = \\theta^7 (1-\\theta)^3$$\n",
    "\n",
    "Okazuje się, że w wypadku prób Bernoulliego (rzutów niesymetryczną monetą) $L$ jest maksymalizowane przez:\n",
    "$$\\theta = \\frac{\\mathrm{liczba~sukcesów}}{\\mathrm{liczba~prób}}$$\n",
    "Innymi słowy, jeśli w $10$ rzutach wypadło $7$ orłów, to szacujemy prawdopodobieństwo wyrzucenia orła na $\\frac{7}{10}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 1 (0,5 pkt)\n",
    "\n",
    "Narysować wykres funkcji $L(\\theta)$ dla $\\theta\\in[0,1]$. Zobaczyć, że maksimum jest w punkcie $\\frac{7}{10}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106d5c250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def L(theta):\n",
    "    return theta ** 7 * (1 - theta) ** 3\n",
    "\n",
    "theta_grid = np.linspace(0, 1, 10) \n",
    "L_values = map(L, theta_grid)\n",
    "_ = plt.plot(theta_grid, L_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 2 (0,5 pkt)\n",
    "\n",
    "Symulator \"prawdziwej\" monety.\n",
    "\n",
    "Napisać funkcję flip_coin, która generuje wynik nb_flips rzutów monetą z prawdopodobieństwem wypadnięcia orła równym theta. Funkcja ma zwrócić tablicę zer i jedynek ($0$ - RESZKA, $1$ - ORZEŁ).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 0, 0, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "\n",
    "def flip_coin(theta, nb_flips):\n",
    "    result = map(lambda x: 1 if random() < theta else 0, range(nb_flips))\n",
    "    assert len(result) == nb_flips\n",
    "    return result\n",
    "\n",
    "print flip_coin(7/10.0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 3 (1 pkt)\n",
    "\n",
    "Pierwszy model generatywny rzutu monetą.\n",
    "\n",
    "Napisać klasę CoinML (Maximum Likelihood) posiadającą metody fit i toss:\n",
    "- fit - przyjmuje listę obserwacji i oblicza self.theta korzystając z wzoru powyżej.\n",
    "- toss - generuje jeden rzut monetą z prawdopodobieństwem self.theta i zwraca 0 lub 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import random\n",
    "\n",
    "class CoinML(object):\n",
    "    def __init__(self):\n",
    "        self.theta = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.theta = X.count(1) / float(len(X))\n",
    "\n",
    "    def toss(self):\n",
    "        return 1 if random() < self.theta else 0\n",
    "\n",
    "model = CoinML()\n",
    "model.fit([0, 1, 0, 0, 0, 1, 1, 1, 0, 1])\n",
    "model.toss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wzór Bayesa\n",
    "\n",
    "Załóżmy teraz, że w \"fabryce monet\" produkowane są tylko monety symetryczne ($\\theta = 0.5$) oraz monety z wadą ($\\theta = 0.6$).\n",
    "\n",
    "W 10 rzutach monetą otrzymaliśmy 7 orłów i 3 reszki. Jak teraz wybrać właściwe $\\theta$?\n",
    "\n",
    "Można np. porównać $L(0.5) < L(0.6)$ i zdecydować się na $\\theta=0.6$.\n",
    "\n",
    "Załóżmy inaczej - wiemy, że średnio co piąta moneta produkowana jest z wadą. Czy wtedy też wybierzemy $\\theta=0.6$? A jeśli tylko jedna na tysiąc jest wadliwa? Jak bardzo nieprawdopodobne musi być to, że nasza moneta jest wadliwa, abyśmy przestali wierzyć funkcji likelihood?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://xkcd.com/1132/\n",
    "\n",
    "https://www.explainxkcd.com/wiki/index.php/1132:_Frequentists_vs._Bayesians\n",
    "\n",
    "<img src=\"figures/L2/frequentists_vs_bayesians.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prawdopodobieństwo warunkowe - przypomnienie\n",
    "\n",
    "https://www.youtube.com/watch?v=H02B3aMNKzE\n",
    "\n",
    "<img src=\"figures/L2/cond_prob.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wzór Bayesa\n",
    "\n",
    "A - parametry rozkładu.\n",
    "B - obserwacja.\n",
    "\n",
    "$$P(A\\mid B) = \\frac{P(B\\mid A)\\,P(A)}{P(B)}$$\n",
    "\n",
    "Wersja rozszerzona, używana np. wtedy (w praktyce zawsze), gdy nie znamy prawdopodobieństwa B, ale znamy je z osobna dla każdego zestawu parametrów A.\n",
    "\n",
    "$$P(B) = {\\sum_j P(B\\mid A_j) P(A_j)}$$\n",
    "$$P(A_i\\mid B) = \\frac{P(B\\mid A_i)\\,P(A_i)}{\\sum\\limits_j P(B\\mid A_j)\\,P(A_j)}$$\n",
    "\n",
    "Prawdopodobieństwa $P(A_i)$ po prawej stronie wzoru nazywamy wiedzą a priori, $P(A_i\\mid B)$ po lewej wiedzą a posteriori. Gdy pojawią się nowe obserwacje, wiedza a posteriori staje się znowu wiedzą a priori i stosujemy wzór Bayesa kolejny raz ($P(A_i\\mid B_{\\mathrm{stare}})$ podstawiamy pod $P(A_i)$ i liczymy $P(A_i\\mid B_{\\mathrm{nowe}})$). Niezależnie od obserwacji $P(B\\mid A_i)$ nie ulega zmianie (dlaczego?).\n",
    "\n",
    "Wróćmy do przykładu, w którym średnio co piąta moneta jest wadliwa. Niech $A_1$ oznacza $\\theta = 0.5$, a $A_2$ oznacza $\\theta = 0.6$. B to nasze obserwacje - siedem orłów i trzy reszki. Wtedy:\n",
    "- $P(A_1) = \\frac45$,\n",
    "- $P(A_2) = \\frac15$,\n",
    "- $P(B\\mid A_1) = (\\frac12)^7(\\frac12)^3 = \\frac{1}{1024}$,\n",
    "- $P(B\\mid A_2) = (\\frac{6}{10})^7(\\frac{4}{10})^3 = \\frac{17496}{9765625}$,\n",
    "- $P(A_1\\mid B) = \\frac{ \\frac45 \\frac{1}{1024} }{ \\frac45 \\frac{1}{1024} + \\frac15 \\frac{17496}{9765625} } \\approx 0.686$\n",
    "- $P(A_2\\mid B) = \\frac{ \\frac15 \\frac{17496}{9765625} }{ \\frac45 \\frac{1}{1024} + \\frac15 \\frac{17496}{9765625} } \\approx 0.314$\n",
    "\n",
    "Czyli wciąż jest około dwa razy większa szansa, że rzucamy symetryczną monetą!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uwaga 1.\n",
    "Obserwacje można podać w dowolnej kolejności, można podawać je po jednej i stosować wzór wielokrotnie, można po kilka, można wszystkie jednocześnie, a wynik będzie ten sam...\n",
    "\n",
    "#### Uwaga 2.\n",
    "...teoretycznie, bo w praktyce jeśli obserwacji jest dużo, to mamy szansę uzyskać błędny wynik ze względu na numeryczną niestabilność."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Najważniejsza rzecz do zrozumienia - robimy rozkład prawdopodobieństwa na rozkładach prawdopodobieństwa!\n",
    "\n",
    "<img src=\"figures/L2/dawg_bayes.jpg\">\n",
    "\n",
    "Nasza moneta jest opisana rozkładem prawdopodobieństwa na dwóch możliwych zdarzeniach elementarnych (wynikach rzutu) {ORZEŁ, RESZKA}:\n",
    "- $P(\\mathrm{ORZEŁ}) = \\theta$,\n",
    "- $P(\\mathrm{RESZKA}) = 1 - \\theta$.\n",
    "\n",
    "Na tych rozkładach robimy drugi rozkład prawdopodobieństwa:\n",
    "- $\\mathcal{P}(\\theta=0.5) = \\frac45$,\n",
    "- $\\mathcal{P}(\\theta=0.6) = \\frac15$.\n",
    "\n",
    "Rozkłady $P$ **nie ulegają zmianie**. Jest to rodzina wszystkich możliwych rozkładów, które bierzemy pod uwagę (w tym wypadku mamy dwa rozkłady dla dwóch różnych $\\theta$; zawsze zakładamy, że dokładnie jeden z nich jest \"prawdziwy\").\n",
    "\n",
    "Rozkład $\\mathcal{P}$ **ulega zmianie** po każdej nowej obserwacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dwa sposoby interpretowania prawdopodobieństwa\n",
    "\n",
    "1. Jako cecha pewnego obiektu ($P$ jest \"wbudowaną\" własnością monety).\n",
    "\n",
    "2. Jako stan naszej wiedzy o świecie ($\\mathcal{P}$ nie jest cechą żadnej istniejącej rzeczy, dlatego może ulegać zmianom).\n",
    "\n",
    "Jeśli interpretujemy $\\mathcal{P}$ jako wiedzę, to nie powinna nas dziwić Uwaga 1.\n",
    "\n",
    "Przy dużej liczbie obserwacji cała gęstość rozkładu $\\mathcal{P}$ zaczyna koncentrować się bardzo blisko wokół prawdziwego $P$.\n",
    "\n",
    "Zazwyczaj jeśli rozkład $P$ zależy od parametrów - w tym wypadku $\\theta$ - to te parametry piszemy w indeksie dolnym. Jeśli rozpatrujemy wszystkie możliwe $\\theta$, to napisalibyśmy, że $\\{P_\\theta\\}_{\\theta\\in[0,1]}$ jest sparametryzowaną rodziną rozkładów prawdopodobieństwa.\n",
    "\n",
    "W bardziej skomplikowanych problemach nie da się sensownie sparametryzować kilkoma liczbami wszystkich możliwych rozkładów prawdopodobieństwa, ale mimo to czasem staramy się to zrobić. Dzięki temu można próbować udowadniać twierdzenia, które zakładają uproszczony obraz świata, a następnie stosować je jako heurystyki.\n",
    "\n",
    "Z punktu widzenia wzoru Bayesa rodzina rozpatrywanych rozkładów prawdopodobieństwa nie musi być wcale sparametryzowana - jeśli mamy zbiór takich rozkładów, to możemy je po prostu ponumerować i piszemy wtedy np. $\\mathcal{P}(P_1) = 0.7, \\mathcal{P}(P_2) = 0.1, \\mathcal{P}(P_3) = 0.15, \\ldots$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uwaga 3.\n",
    "\n",
    "Jeśli przyjmiemy, że pewien rozkład $P$ ma a priori $\\mathcal{P}$ równe zero, to $\\mathcal{P}$ a posteriori też będzie równe zero, niezależnie od siły dowodów przemawiających za tym konkretnym $P$. Dlatego nie należy wykluczać a priori żadnego $P$, jeśli nie jesteśmy całkowicie pewni, że jest ono niemożliwe.\n",
    "\n",
    "Przy braku wiedzy a priori trzeba tak dobrać $\\mathcal{P}$, aby wszędzie było niezerowe (np. jeśli bierzemy pod uwagę $n$ różnych rozkładów $P$, to $\\mathcal{P}$ jest równe stale $\\frac1n$; jeśli rozkłady są sparametryzowane odcinkiem $[a,b]$, to $\\mathcal{P}$ jest rozkładem jednostajnym na tym odcinku; jeśli rozkłady są sparametryzowane całą prostą rzeczywistą, to $\\mathcal{P}$ oczywiście nie może być rozkładem jednostajnym, wtedy używamy np. rozkładu Gaussa o średniej zero i wariancji jeden; itd.).\n",
    "\n",
    "#### Uwaga 4.\n",
    "\n",
    "W wypadku rzutu monetą mamy tylko dwa możliwe zdarzenia elementarne, więc wszystkie rozkłady można sparametryzować odcinkiem $[0,1]$.\n",
    "\n",
    "Dla kostki sześciennej jest podobnie - jest sześć zdarzeń elementarnych, więc wszystkie rozkłady można sparametryzować szóstkami nieujemnych liczb rzeczywistych, które sumują się do jedności (5-wymiarowy sympleks w $\\mathbb{R}^6$).\n",
    "\n",
    "W obu powyższych przypadkach zdarzeń elementarnych jest skończenie wiele, a możliwych rozkładów continuum.\n",
    "\n",
    "Ale co się dzieje, gdy zdarzeń elementarnych jest nieskończenie wiele? Można np. powiedzieć, że przestrzeń kolorów jest ciągła i wtedy wszystkich możliwych obrazków jest nieskończenie wiele (continuum). Da się udowodnić, że możliwych rozkładów prawdopodobieństwa $P$ wciąż jest continuum, ale ciężko nadać im jakąkolwiek strukturę i zdefiniować $\\mathcal{P}$ jako rozkład jednostajny na niej."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podejście maximum a posteriori\n",
    "\n",
    "Zasada postępowania jest prosta:\n",
    "1. Mamy dany pewien rozkład a priori oraz obserwacje.\n",
    "2. Korzystając ze wzoru Bayesa obliczamy rozkład a posteriori.\n",
    "3. Wybieramy ten rozkład $P$, którego prawdopodobieństwo a posteriori jest największe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 4 (1 pkt)\n",
    "\n",
    "Napisać klasę CoinMAP (Maximum A Posteriori) posiadającą metody fit i toss:\n",
    "- konstruktor - przyjmuje prior, który może np. być słownikiem (klucz - $\\theta$, wartość - jej prawdopodobieństwo a priori),\n",
    "- fit - przyjmuje listę obserwacji i uaktualnia self.knowledge, korzystając ze wzoru Bayesa, a następnie ustawia self.theta wybierając odpowiednią wartość z self.knowledge,\n",
    "- toss - generuje jeden rzut monetą z prawdopodobieństwem self.theta i zwraca 0 lub 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.685566763155\n",
      "Powinno wyjść 1: 1.0\n",
      "0.37285027427\n",
      "Powinno wyjść 1: 1.0\n"
     ]
    }
   ],
   "source": [
    "class CoinMAP(object):\n",
    "    def __init__(self, prior):\n",
    "        self.knowledge = prior\n",
    "        self.theta = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.knowledge = self.__calculate_knowledge(X)\n",
    "        self.theta = max(self.knowledge.values())\n",
    "\n",
    "    def toss(self):\n",
    "        return 1 if random() < self.theta else 0\n",
    "    \n",
    "    def __calculate_knowledge(self, X):\n",
    "        priors = self.__calculate_priors(X)\n",
    "        summ = sum(map(lambda x: x[0] * x[1], zip(priors.values(), self.knowledge.values())))\n",
    "        return dict(map(lambda (k, v): (k, (v * priors[k]) / summ), self.knowledge.iteritems()))\n",
    "    \n",
    "    def __calculate_priors(self, X):\n",
    "        theta = X.count(1) / float(len(X))\n",
    "        return dict(map(self.__prior_lambda(theta), self.knowledge.iteritems()))\n",
    "    \n",
    "    def __prior_lambda(self, theta):\n",
    "        return lambda (k, v): (k, k ** (theta * 10) * (1 - k) ** ((1 - theta) * 10))\n",
    "\n",
    "\n",
    "model = CoinMAP({0.5: 0.8, 0.6: 0.2})\n",
    "model.fit([1,0,1,1,1,0,0,1,1,1])\n",
    "print model.theta\n",
    "print \"Powinno wyjść 1:\", sum(model.knowledge.values())\n",
    "\n",
    "model = CoinMAP({0.5: 0.5, 0.6: 0.2, 0.8: 0.3})\n",
    "model.fit([1,0,1,1,1,0,0,1,1,1])\n",
    "print model.theta\n",
    "print \"Powinno wyjść 1:\", sum(model.knowledge.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jedyne Słuszne Podejście - całka po rozkładzie a posteriori\n",
    "\n",
    "Dotychczas korzystaliśmy tylko z części wiedzy na temat rozkładów - dlaczego nie użyć jej całej?\n",
    "\n",
    "Jeśli wiemy, że z prawdopodobieństwem 0.686 prawdopodobieństwo wypadnięcia orła wynosi 0.5, a z prawdopodobieństwem 0.314 prawdopodobieństwo wypadnięcia orła wynosi 0.6, to jakie jest ostateczne prawdopodobieństwo wypadnięcia orła?\n",
    "\n",
    "$$P(\\mathrm{ORZEŁ}) = \\mathcal{P}(\\theta = 0.5)P(\\mathrm{ORZEŁ} \\mid \\theta = 0.5) + \\mathcal{P}(\\theta = 0.6)P(\\mathrm{ORZEŁ} \\mid \\theta = 0.6) = 0.686 * 0.5 + 0.314 * 0.6 \\approx 0.531 $$\n",
    "\n",
    "W wersji z większą liczbą możliwych wartości $\\theta$:\n",
    "$$P(\\mathrm{ORZEŁ}) = \\sum_{\\theta_j} \\mathcal{P}(\\theta = \\theta_j)P(\\mathrm{ORZEŁ} \\mid \\theta = \\theta_j) = \\sum_{\\theta_j} \\mathcal{P}(\\theta = \\theta_j)\\theta_j $$\n",
    "\n",
    "#### Uwaga 5.\n",
    "\n",
    "Opisane tu podejście jest jedynym poprawnym sposobem uczenia się rozkładu danych na podstawie obserwacji. Nie będzie niespodzianką fakt, że w praktyce jest ono niewykonalne..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 5 (2 pkt)\n",
    "\n",
    "Napisać klasę CoinBest, która działa jak CoinMAP z tą różnicą, że self.theta jest obliczane powyższym wzorem, a nie wybierane spośród wartości self.knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.531443323685\n",
      "Powinno wyjść 1: 1.0\n",
      "0.638398817627\n",
      "Powinno wyjść 1: 1.0\n"
     ]
    }
   ],
   "source": [
    "class CoinBest(object):\n",
    "    def __init__(self, prior):\n",
    "        self.knowledge = prior\n",
    "        self.theta = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.knowledge = self.__calculate_knowledge(X)\n",
    "        self.theta = self.__calculate_theta()\n",
    "\n",
    "    def toss(self):\n",
    "        return 1 if random() < self.theta else 0\n",
    "    \n",
    "    def __calculate_knowledge(self, X):\n",
    "        priors = self.__calculate_priors(X)\n",
    "        summ = sum(map(lambda x: x[0] * x[1], zip(priors.values(), self.knowledge.values())))\n",
    "        return dict(map(lambda (k, v): (k, (v * priors[k]) / summ), self.knowledge.iteritems()))\n",
    "    \n",
    "    def __calculate_priors(self, X):\n",
    "        theta = X.count(1) / float(len(X))\n",
    "        return dict(map(self.__prior_lambda(theta), self.knowledge.iteritems()))\n",
    "    \n",
    "    def __prior_lambda(self, theta):\n",
    "        return lambda (k, v): (k, k ** (theta * 10) * (1 - k) ** ((1 - theta) * 10))\n",
    "    \n",
    "    def __calculate_theta(self):\n",
    "        return sum(map(lambda x: x[0] * x[1], zip(self.knowledge.keys(), self.knowledge.values())))\n",
    "\n",
    "\n",
    "model = CoinBest({0.5: 0.8, 0.6: 0.2})\n",
    "model.fit([1,0,1,1,1,0,0,1,1,1])\n",
    "print model.theta\n",
    "print \"Powinno wyjść 1:\", sum(model.knowledge.values())\n",
    "\n",
    "model = CoinBest({0.5: 0.5, 0.6: 0.2, 0.8: 0.3})\n",
    "model.fit([1,0,1,1,1,0,0,1,1,1])\n",
    "print model.theta\n",
    "print \"Powinno wyjść 1:\", sum(model.knowledge.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Porównanie powyższych metod\n",
    "\n",
    "Wybiegnijmy trochę do przodu:\n",
    "- ML jest najgorsze, ale najprostsze,\n",
    "- ML z sensowną regularyzacją ma przybliżać MAP,\n",
    "- MAP przy dużej liczbie obserwacji przybliża całkę po rozkładzie a posteriori.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metoda Monte Carlo\n",
    "(tak naprawdę metody, bo jest ich wiele, ale wszystkie opierają się na jednym prostym pomyśle)\n",
    "\n",
    "Przykład:\n",
    "\n",
    "Załóżmy, że opracowaliśmy nową strategię gry w Blackjacka, która zakłada m.in. zliczanie schodzących kart. Zanim zaczniemy stosować ją w kasynie chcemy upewnić się, że faktycznie jest ona skuteczna, to znaczy średnia wygrana jest większa od zera (albo średnia wygrana na godzinę gry jest większa od płacy minimalnej).\n",
    "\n",
    "Krupier gra deterministycznie, więc przebieg gry zależy tylko i wyłącznie od kolejności kart w talii. Niestety, takich ułożeń jest bardzo dużo, a ponadto zasady Blackjacka przewidują kilka specjalnych sytuacji, przez co bardzo ciężko (jeśli jest to w ogóle możliwe) zapisać wzór na średnią wygraną. Co zrobić w takiej sytuacji?\n",
    "\n",
    "Rozwiązanie:\n",
    "\n",
    "Skoro krupier jest deterministyczny, to rozgrywamy bardzo dużo (im więcej, tym lepiej) gier z symulowanym krupierem i uśredniamy wygrane.\n",
    "\n",
    "Monte Carlo!\n",
    "\n",
    "#### Uwaga 6.\n",
    "\n",
    "Jeśli tylko da się nie używać Monte Carlo, to należy nie używać Monte Carlo. Ale zazwyczaj się nie da."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paradoks Monty'ego Halla\n",
    "\n",
    "Przeliczmy jeszcze raz przykład z wykładu, korzystając ze wzoru Bayesa.\n",
    "\n",
    "Przypomnienie:\n",
    "\n",
    "Mamy trzy bramki, za jedną z nich znajduje się nagroda, za pozostałymi dwiema koza. Gracz wybiera jedną z trzech bramek. Prowadzący grę, który zna położenie nagrody, odsłania jedną z pozostałych dwóch bramek, przy czym zawsze w odsłoniętej bramce znajduje się koza. Gracz ma teraz możliwość zmiany bramki.\n",
    "\n",
    "Wersja z piorunem: po wybraniu bramki piorun trafia losowo w jedną z pozostałych dwóch i odsłania jej zawartość. Gracz ma możliwość zmiany bramki na drugą zasłoniętą.\n",
    "\n",
    "Zastanówmy się chwilę, jak zdefiniować $P$ i $\\mathcal{P}$. Interesującą nas wielkością jest prawdopodobieństwo wygranej po wybraniu pewnej ustalonej bramki. Załóżmy na chwilę, że nagroda znajduje się w pierwszej bramce. Wtedy prawdopodobieństwo wygranej przy wybraniu pierwszej bramki wynosi 100%, natomiast w wypadku drugiej i trzeciej jest to oczywiście 0%. Mówienie w tym miejscu o prawdopodobieństwach może wydawać się sztuczne, ale jest to konieczne, aby móc zastosować wzór Bayesa. Możemy myśleć o trzech bramkach jako o trzech monetach, z których dokładnie jedna ma $\\theta = 1$, a pozostałe dwie $0$.\n",
    "\n",
    "Jeśli trzy bramki zwracają nagrody z prawdopodobieństwami odpowiednio $\\theta_1$, $\\theta_2$ i $\\theta_3$, to zapiszemy taką sytuację jako:\n",
    "$$P \\sim (\\theta_1, \\theta_2, \\theta_3)$$\n",
    "\n",
    "W takim razie mamy dokładnie trzy możliwości:\n",
    "- $P_1 \\sim (1,0,0)$,\n",
    "- $P_2 \\sim (0,1,0)$,\n",
    "- $P_3 \\sim (0,0,1)$.\n",
    "\n",
    "Każda z nich jest a priori jednakowo prawdopodobna, możemy więc zapisać:\n",
    "- $\\mathcal{P}(P_1) = \\frac13$,\n",
    "- $\\mathcal{P}(P_2) = \\frac13$,\n",
    "- $\\mathcal{P}(P_3) = \\frac13$.\n",
    "\n",
    "Załóżmy teraz, że gracz wybrał na początku bramkę nr 1. Prowadzący odsłonił bramkę nr 2 i była tam koza. Jak zmieniła się wartość $\\mathcal{P}$? Zauważmy, że:\n",
    "- $P(\\mathrm{obserwacja}\\mid P_1) = \\frac12$ - ponieważ jeśli nagroda jest w pierwszej bramce, to prowadzący losowo odsłania bramkę nr 2 lub nr 3,\n",
    "- $P(\\mathrm{obserwacja}\\mid P_2) = 0$ - nagroda nie może być w bramce z kozą,\n",
    "- $P(\\mathrm{obserwacja}\\mid P_3) = 1$ - prowadzący musi odsłonić bramkę nr 2.\n",
    "\n",
    "Podstawiając do wzoru Bayesa (proszę przeliczyć to przynajmniej raz na kartce) otrzymamy ostatecznie:\n",
    "- $\\mathcal{P}(P_1\\mid\\mathrm{obserwacja}) = \\frac13$,\n",
    "- $\\mathcal{P}(P_2\\mid\\mathrm{obserwacja}) = 0$,\n",
    "- $\\mathcal{P}(P_3\\mid\\mathrm{obserwacja}) = \\frac23$\n",
    "\n",
    "na końcu dla każdej bramki liczymy prawdopodobieństwo wylosowania nagrody po wyborze tejże bramki - oczywiście w tym celu liczymy całkę po rozkładzie a posteriori i otrzymujemy prawdopodobieństwa: $\\frac13 * 1 + 0 * 0 + \\frac23 * 0 = \\frac13, \\frac13 * 0 + 0 * 1 + \\frac23 * 0 = 0, \\frac13 * 0 + 0 * 0 + \\frac23 * 1 = \\frac23$. Dlatego opłaca się zmienić bramkę na trzecią.\n",
    "\n",
    "Wersja z piorunem: gracz wybrał na początku bramkę nr 1. Piorun uderzył w bramkę nr 2 i była tam koza. Jak zmieniła się wartość $\\mathcal{P}$? Zauważmy, że:\n",
    "- $P(\\mathrm{obserwacja}\\mid P_1) = \\frac12$ - piorun uderza losowo,\n",
    "- $P(\\mathrm{obserwacja}\\mid P_2) = 0$ - nagroda nie może być w bramce z kozą,\n",
    "- $P(\\mathrm{obserwacja}\\mid P_3) = \\frac12$ - piorun uderza losowo.\n",
    "\n",
    "Podstawiając do wzoru Bayesa (proszę przeliczyć to przynajmniej drugi raz na kartce) otrzymamy ostatecznie:\n",
    "- $\\mathcal{P}(P_1\\mid\\mathrm{obserwacja}) = \\frac12$,\n",
    "- $\\mathcal{P}(P_2\\mid\\mathrm{obserwacja}) = 0$,\n",
    "- $\\mathcal{P}(P_3\\mid\\mathrm{obserwacja}) = \\frac12$\n",
    "\n",
    "a po policzeniu całek po rozkładzie a posteriori otrzymamy prawdopodobieństwa $\\frac12, 0, \\frac12$ i dlatego nie ma znaczenia, czy zmienimy bramkę na trzecią.\n",
    "\n",
    "Pytanie kontrolne - dlaczego musimy liczyć całki po rozkładzie a posteriori, skoro wynik wychodzi taki sam, jak rozkład a posteriori?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 6 (1 pkt)\n",
    "\n",
    "Zasymulować metodą Monte Carlo przebieg rozgrywki dla gracza, który:\n",
    "- nie zmienia bramki,\n",
    "- zawsze zmienia bramkę,\n",
    "\n",
    "w przypadku:\n",
    "- zwykłym,\n",
    "- z piorunem, a jeśli trafi w nagrodę to:\n",
    "\t- powtórka,\n",
    "\t- przegrana.\n",
    "\n",
    "Wypisać średnią wygraną."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------\n",
      "--------------- Monty Hall ---------------\n",
      "A player changes the chosen door:  0.1677\n",
      "A player stays at the first door:  0.3314\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "---------- Lightning Monty Hall ----------\n",
      "A player changes the chosen door:  0.1666\n",
      "A player stays at the first door:  0.1603\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "\n",
      "------------------------------------------\n",
      "--- Lightning Monty Hall with retries ----\n",
      "A player changes the chosen door:  0.165\n",
      "A player stays at the first door:  0.3237\n",
      "------------------------------------------\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class MontyHallSimulator:\n",
    "    def __init__(self, iterations = None):\n",
    "        self.iterations = iterations\n",
    "        if iterations is None: self.iterations = 10000\n",
    "            \n",
    "    def pick_door(self):\n",
    "        return random.randint(0, 2)\n",
    "    \n",
    "    def pick_winning_door(self):\n",
    "        self.winning_door = self.pick_door()\n",
    "\n",
    "    def pick_players_door(self):\n",
    "        self.players_door = self.pick_door()\n",
    "    \n",
    "    def pick_open_door(self):\n",
    "        self.open_door = self.pick_door()\n",
    "        while self.open_door == self.winning_door or self.open_door == self.players_door:\n",
    "            self.open_door = self.pick_door()\n",
    "    \n",
    "    def change_door(self):\n",
    "        self.players_door = 3 - self.open_door - self.players_door # 0 + 1 + 2 = 3\n",
    "        \n",
    "    def settle_the_game(self):\n",
    "        return 1 if self.players_door < self.winning_door else 0\n",
    "\n",
    "    def call(self, change_door):\n",
    "        results = []\n",
    "        for i in range(self.iterations):\n",
    "            self.pick_players_door()\n",
    "            self.pick_winning_door()\n",
    "            self.pick_open_door()\n",
    "            if self.open_door == self.winning_door:\n",
    "                results.append(0)\n",
    "                continue\n",
    "            if change_door: self.change_door()\n",
    "            results.append(self.settle_the_game())\n",
    "        return results.count(1) / float(self.iterations)\n",
    "\n",
    "class LightningMontyHallSimulator(MontyHallSimulator):\n",
    "    def __init__(self, retry, iterations = None):\n",
    "        MontyHallSimulator.__init__(self, iterations)\n",
    "        self.retry = retry\n",
    "        \n",
    "    def pick_open_door(self):\n",
    "        self.open_door = self.pick_door()\n",
    "        if self.retry:\n",
    "            while self.open_door == self.winning_door or self.open_door == self.players_door:\n",
    "                self.open_door = self.pick_door()\n",
    "        else:\n",
    "            while self.open_door == self.players_door:\n",
    "                self.open_door = self.pick_door()\n",
    "            \n",
    "\n",
    "simulator = MontyHallSimulator()\n",
    "print '\\n------------------------------------------'\n",
    "print '--------------- Monty Hall ---------------'\n",
    "print 'A player changes the chosen door: ', simulator.call(change_door = True)\n",
    "print 'A player stays at the first door: ', simulator.call(change_door = False)\n",
    "print '------------------------------------------'\n",
    "print '------------------------------------------\\n'\n",
    "\n",
    "lightning_simulator = LightningMontyHallSimulator(retry = False)\n",
    "print '------------------------------------------'\n",
    "print '---------- Lightning Monty Hall ----------'\n",
    "print 'A player changes the chosen door: ', lightning_simulator.call(change_door = True)\n",
    "print 'A player stays at the first door: ', lightning_simulator.call(change_door = False)\n",
    "print '------------------------------------------'\n",
    "print '------------------------------------------\\n'\n",
    "\n",
    "lightning_simulator_with_retries = LightningMontyHallSimulator(retry = True)\n",
    "print '------------------------------------------'\n",
    "print '--- Lightning Monty Hall with retries ----'\n",
    "print 'A player changes the chosen door: ', lightning_simulator_with_retries.call(change_door = True)\n",
    "print 'A player stays at the first door: ', lightning_simulator_with_retries.call(change_door = False)\n",
    "print '------------------------------------------'\n",
    "print '------------------------------------------'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 7 (1 pkt)\n",
    "\n",
    "Losujemy $k=100$ razy liczbę od $1$ do $m=200$ z rozkładem jednostajnym. Ile średnio różnych liczb wylosujemy?\n",
    "Rozwiązać metodą Monte Carlo.\n",
    "\n",
    "https://math.dartmouth.edu/archive/m19w03/public_html/Section6-5.pdf - czy wynik zgadza się z tw. 6.14?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f(k, m, nb_simulations):\n",
    "    ...\n",
    "    return avg_nb_integers\n",
    "\n",
    "k = ...\n",
    "m = ...\n",
    "print f(k, m, nb_simulations=...), \"=?=\", m - (k * (1 - 1/float(k))**m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rozkład Gaussa - przypomnienie\n",
    "\n",
    "Spróbujmy zaprzyjaźnić się z n-wymiarowym rozkładem Gaussa.\n",
    "\n",
    "wzór na gęstość rozkładu gaussa:\n",
    "\n",
    "$$f(x \\; | \\; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\sigma^2\\pi} } \\; e^{ -\\frac{(x-\\mu)^2}{2\\sigma^2} }$$\n",
    "\n",
    "wersja n-wymiarowa:\n",
    "https://en.wikipedia.org/wiki/Multivariate_normal_distribution\n",
    "\n",
    "Macierz kowariancji rozkładu n-wymiarowego musi być dodatnio określona."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 8 (2 pkt)\n",
    "\n",
    "Napisać funkcję, która przyjmuje parametry rozkładu normalnego: średnią oraz macierz kowariancji, liczbę sampli, a następnie sampluje punkty z tego rozkładu i rysuje na plaszczyźnie. Ponadto na rysunku należy zaznaczyć strzałkami wektory własne macierzy kowariancji (punkt zaczepienia to średnia rozkładu normalnego) i wypisać odpowiadające im wartości własne.\n",
    "\n",
    "Narysować powyższe dla kilku różnych losowo wybranych średnich i macierzy kowariancji (http://stackoverflow.com/questions/619335/a-simple-algorithm-for-generating-positive-semidefinite-matrices).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = ...\n",
    "cov = ...\n",
    "samples = numpy.random.multivariate_normal(mean, cov, size=...)\n",
    "# eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "w, v = np.linalg.eig(cov)\n",
    "...\n",
    "plot\n",
    "\n",
    "# wynik: spodziewamy się elipsy o środku w średniej rozkładu,\n",
    "# tam też powinna być największa gęstość samplowanych punktów;\n",
    "# wektory własne powinny wskazywać kierunki osi elipsy;\n",
    "# jaki jest związek wartości własnych z długościami osi elipsy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie 9 (4 pkt)\n",
    "\n",
    "Załóżmy, że mamy dane pochodzące dwuwymiarowego rozkładu normalnego o macierzy kowariancji będącej identycznością i średniej $\\mu$. Będziemy estymowali $\\mu$ korzystając z wzoru Bayesa.\n",
    "\n",
    "1. Stworzyć siatkę 100x100 na kwadracie $[0,1]^2$ - to będą nasze potencjalne średnie.\n",
    "2. Wylosować jeden punkt z siatki - to będzie \"prawdziwa\" średnia rozkładu. Oczywiście model jej nie zna.\n",
    "3. Przyjąć jednostajny rozkład a priori (użyć floatów z największą możliwą precyzją), trzymać go w tablicy knowledge.\n",
    "4. Powtórzyć nb_iters razy:\n",
    "    - wygenerować nb_samples sampli z prawdziwego rozkładu,\n",
    "    - uaktualnić knowledge na podstawie obserwacji,\n",
    "    - narysować knowledge jako dwuwymiarowy heatmap.\n",
    "\n",
    "Sprawdzić, co się stanie, gdy:\n",
    "1. Siatka punktów będzie rzadsza, a prawdziwa średnia rozkładu będzie poza siatką.\n",
    "2. Średnia rozkładu znajdzie się całkowicie poza badanym kwadratem, np. w punkcie $(1.2, 0.7)$.\n",
    "3. Na początku wylosujemy 2 punkty z siatki - $\\mu_1$ i $\\mu_2$ - a następnie obserwacje będziemy samplować naprzemian z dwóch rozkładów gaussa, przy czym cały czas estymujemy $\\mu$ tak, jak gdyby istniało dokładnie jedno prawdziwe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
